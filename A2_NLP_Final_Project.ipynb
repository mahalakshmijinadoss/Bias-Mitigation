{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Trying to implement the CMU paper this time (page 17 of https://aclanthology.org/2020.socialnlp-1.pdf)\n",
        "\n",
        "\n",
        "```\n",
        "Model Architecture\n",
        "Our demotion model consists of three parts:\n",
        "1) An encoder H that encodes the text into a high dimensional space;\n",
        "2) A binary classifier C that predicts the target attribute from\n",
        "the input text;\n",
        "3) An adversary D that predicts the protected attribute from the input text.\n",
        "\n",
        "We used a single-layer bidirectional LSTM encoder with an attention mechanism.\n",
        "Both classifiers are two-layer MLPs with a tanh activation function.\n",
        "```\n",
        "\n",
        "LSTM can be made bidirectional: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "\n",
        "PyTorch has MultiheadAttention implementation: https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html\n",
        "\n",
        "MLP == Linear layer: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n",
        "\n",
        "tanh activation: https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html?highlight=tanh#torch.nn.Tanh\n",
        "\n",
        "HW4 template code also featured a BidirectionalEncoder class, but it was the Decoder class that implemented attention.\n",
        "\n",
        "Found the code the CMU paper is based on!!\n",
        "https://github.com/Sachin19/adversarial-classify/blob/master/model.py\n",
        "\n",
        "Their paper: https://arxiv.org/pdf/1909.00453.pdf\n"
      ],
      "metadata": {
        "id": "pso9C1UuZJvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install HuggingFace transformers library to match baseline\n",
        "\n",
        "# !pip install transformers[sentencepiece]==4.18.0 datasets --q"
      ],
      "metadata": {
        "id": "i-Bq5OMErmBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# from transformers import AutoTokenizer\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score, precision_score, confusion_matrix\n",
        "import warnings\n",
        "from torch.autograd import Function, Variable\n",
        "import math\n",
        "from torchtext.vocab import vocab\n",
        "from torchtext.data import get_tokenizer\n",
        "from collections import Counter, OrderedDict\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
        "import copy\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "iQP5W5Wtoe1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify GPU device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqG6KmqkKWXg",
        "outputId": "a9fc11c0-a8ee-4849-81c3-590c198b057c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "QqzIEtvfoVFv",
        "outputId": "2e9042d4-079b-4a26-ced6-459fc4f80853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  target                                       comment_text  \\\n",
              "0         185       0  Should they have to? \\n\\nChristians, whether a...   \n",
              "1         847       0  The Militia holding a anti-Government stand-of...   \n",
              "2         933       0  In regard to the WW review of the Glenn Beck a...   \n",
              "3        1073       0  When you can figure out that turbans are worn ...   \n",
              "4        1117       0  What is uniquely and exclusively possible in a...   \n",
              "\n",
              "   muslim  christian  religion  \n",
              "0       0          1         0  \n",
              "1       0          1         0  \n",
              "2       0          1         0  \n",
              "3       1          0         1  \n",
              "4       0          1         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df810e05-532c-4188-8eee-c894ca0a4537\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>target</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>muslim</th>\n",
              "      <th>christian</th>\n",
              "      <th>religion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>185</td>\n",
              "      <td>0</td>\n",
              "      <td>Should they have to? \\n\\nChristians, whether a...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>847</td>\n",
              "      <td>0</td>\n",
              "      <td>The Militia holding a anti-Government stand-of...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>933</td>\n",
              "      <td>0</td>\n",
              "      <td>In regard to the WW review of the Glenn Beck a...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1073</td>\n",
              "      <td>0</td>\n",
              "      <td>When you can figure out that turbans are worn ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1117</td>\n",
              "      <td>0</td>\n",
              "      <td>What is uniquely and exclusively possible in a...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df810e05-532c-4188-8eee-c894ca0a4537')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df810e05-532c-4188-8eee-c894ca0a4537 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df810e05-532c-4188-8eee-c894ca0a4537');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Connect to Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Read subset (100 items) csv file from Google Drive\n",
        "# train_data = pd.read_csv('/content/drive/Shareddrives/AI539: NLP with Deep Learning/subset_baseline_data.csv')\n",
        "\n",
        "# Training data will be split into 75% train and 25% validation\n",
        "train_data = pd.read_csv(\"/content/drive/My Drive/train_religion.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/My Drive/test_religion.csv\")\n",
        "\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Dataset class for our data\n",
        "# No need for the BERT tokenizer for this architecture though\n",
        "# Need to take vocab approach like in the HWs instead\n",
        "# data is already provided where targets are associated with comments\n",
        "# need to build vocab from the comments though\n",
        "# and need to return protected attribute along with target label and text\n",
        "\n",
        "class ToxicityDataset(Dataset):\n",
        "    def __init__(self, all_data, split=\"train\", tokenizer=None, text_vocab=None):\n",
        "        self.raw_data = None\n",
        "        self.tokens = None\n",
        "        self.target_labels = None\n",
        "        self.protected_labels = None\n",
        "        # self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased') if tokenizer is None else tokenizer\n",
        "        self.tokenizer = get_tokenizer(\"basic_english\") if tokenizer is None else tokenizer\n",
        "        self.text_vocab = text_vocab\n",
        "\n",
        "        # do data cleaning, tokenizing, make sure all are tensors\n",
        "\n",
        "        # train set: 75% train, 25% val, test set: 100% test\n",
        "        split_index = round(0.75*len(all_data))\n",
        "        if split == \"test\":\n",
        "            # No modifications, use all of the test data\n",
        "            self.raw_data = all_data\n",
        "        elif split == \"train\":\n",
        "            # 75% of train data for training\n",
        "            self.raw_data = pd.DataFrame(all_data.loc[:split_index, :]).reset_index()\n",
        "        else:\n",
        "            # 25% of train data for validation\n",
        "            self.raw_data = pd.DataFrame(all_data.loc[split_index:, :]).reset_index()\n",
        "\n",
        "        # drop empty comments\n",
        "        self.raw_data['comment_text'].dropna(inplace=True)\n",
        "\n",
        "        # preprocess comments\n",
        "        self.raw_data.loc[:, 'comment_text'] = self.raw_data['comment_text'].apply(self._preprocess_comments)\n",
        "\n",
        "        # create vocabulary from training data\n",
        "        if self.text_vocab == None:\n",
        "            word_counter = Counter()\n",
        "            for text in self.raw_data[\"comment_text\"]:\n",
        "                word_counter.update(text.split())\n",
        "            sorted_word_counter = sorted(word_counter.items(), key=lambda x: x[1], reverse=True)\n",
        "            ordered_words = OrderedDict(sorted_word_counter)\n",
        "            self.text_vocab = vocab(ordered_words, min_freq=5, specials=['<unk>'], special_first=True)\n",
        "            self.text_vocab.set_default_index(self.text_vocab['<unk>'])\n",
        "\n",
        "        # tokenize using the tokenizer, not sure if this is really correct or not\n",
        "        comments = list(self.raw_data['comment_text'].copy())\n",
        "        self.tokens = []\n",
        "        for comment in self.raw_data['comment_text']:\n",
        "            self.tokens.append(self.text_vocab.forward(self.tokenizer(comment)))\n",
        "\n",
        "        # convert targets from a range to binary classes\n",
        "        self.target_labels = self.raw_data['target'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
        "\n",
        "        # currently the only protected attribute is \"female\", but for intersectional\n",
        "        # bias we'd probably want multiple protected attributes\n",
        "        self.protected_labels = self.raw_data['muslim']\n",
        "\n",
        "\n",
        "    def _preprocess_comments(self, comment):\n",
        "        new_tokens = []\n",
        "        for token in comment.split(\" \"):\n",
        "            # replace usernames with something generic\n",
        "            token = '@user' if token.startswith('@') and len(token) > 1 else token\n",
        "\n",
        "            # replace URLs with something generic\n",
        "            token = 'http' if token.startswith('http') else token\n",
        "\n",
        "            new_tokens.append(token)\n",
        "        return \" \".join(new_tokens)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "            torch.tensor(self.tokens[index]),\n",
        "            torch.tensor(self.target_labels[index]),\n",
        "            torch.tensor(self.protected_labels[index])\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target_labels)\n",
        "\n",
        "    # From HW2\n",
        "    def pad_collate(self, batch):\n",
        "        (text_lists, label_lists, protected_lists) = zip(*batch)\n",
        "\n",
        "        numeralized_text = [torch.tensor(t) for t in text_lists]\n",
        "        x_lens = [len(x) for x in numeralized_text]\n",
        "        xx = pad_sequence(numeralized_text, batch_first=True, padding_value=0).type(torch.int)\n",
        "\n",
        "        # numeralized_tags = [F.one_hot(torch.tensor(self.tag_vocab.forward(t)).long(), num_classes=len(self.tag_vocab)) for t in label_lists]\n",
        "        # yy = pad_sequence(numeralized_tags, batch_first=True, padding_value=0).type(torch.float)\n",
        "\n",
        "        # target labels and protected labels should be the same size\n",
        "        yy = torch.tensor(label_lists, dtype=int)\n",
        "        zz = torch.tensor(protected_lists, dtype=int)\n",
        "\n",
        "        return xx, x_lens, yy, zz\n",
        "\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "train_dataset = ToxicityDataset(train_data, split=\"train\", tokenizer=tokenizer)\n",
        "val_dataset = ToxicityDataset(train_data, split=\"val\", tokenizer=tokenizer, text_vocab=train_dataset.text_vocab)\n",
        "test_dataset = ToxicityDataset(test_data, split=\"test\", tokenizer=tokenizer, text_vocab=train_dataset.text_vocab)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=train_dataset.pad_collate)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True, collate_fn=train_dataset.pad_collate)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True, collate_fn=train_dataset.pad_collate)\n"
      ],
      "metadata": {
        "id": "YMOrxmJ2reuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train dataset has length:\", len(train_dataset))\n",
        "print(\"Val dataset has length:\", len(val_dataset))\n",
        "\n",
        "print(\"One item from train dataset:\", train_dataset[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak7Lxt4B9G5j",
        "outputId": "7dfa1e12-09e2-499f-a16e-b98367e31e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset has length: 30001\n",
            "Val dataset has length: 10000\n",
            "One item from train dataset: (tensor([   69,    22,    18,     2,   651,  2291,   428,   360,    15,     5,\n",
            "          366,   428,    23,  4403,    24,  3727,    42,   127,  2584,     2,\n",
            "          139,     5,  3810,   165,    53,     5,   163,   428,    67,   163,\n",
            "          428,    91,     2,  1096,    37,  4986,   428,    23,     0,   428,\n",
            "          159,   130,     5,  1403, 16902,    27,  1496,    22,    42,   127,\n",
            "           18,   130,    10,   258,   524,   165,   142,     8,   887,   120,\n",
            "           16,   428,   693,     8,    42,    14,     5,   121,   234,   160,\n",
            "           29,   165]), tensor(0), tensor(0))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Anita's attempt before finding Kumar et al. code\n",
        "# Based on HW4 skeleton code\n",
        "'''\n",
        "class EncoderAndClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, enc_hid_dim, embed_dim, num_heads, output_dim, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.enc_hidden_dim = enc_hid_dim\n",
        "        self.emb = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
        "        self.bilstm = nn.GRU(embed_dim, enc_hid_dim, bidirectional = True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear1 = nn.Linear(2 * enc_hid_dim, 128)\n",
        "        self.linear2 = nn.Linear(128, output_dim)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # embed input tokens\n",
        "        embedded = self.dropout(self.emb(input))\n",
        "\n",
        "        # process with bidirectional GRU model\n",
        "        enc_hidden_states, _ = self.bilstm(embedded)\n",
        "\n",
        "        # compute a global sentence representation to feed as the initial hidden state of the decoder\n",
        "        # concatenate the forward GRU's representation after the last word and\n",
        "        # the backward GRU's representation after the first word\n",
        "\n",
        "        last_forward = enc_hidden_states[-1, :, :self.enc_hidden_dim]\n",
        "        first_backward = enc_hidden_states[0, :, self.enc_hidden_dim:]\n",
        "\n",
        "        # this was from the skeleton code\n",
        "        # transform to the size of the decoder hidden state with a fully-connected layer\n",
        "        # sent = F.relu(self.fc(torch.cat((last_forward, first_backward), dim = 1)))\n",
        "\n",
        "        # should be this instead?\n",
        "        l1_output = self.linear1(torch.cat((last_forward, first_backward), dim = 1))\n",
        "        tanh_output = F.tanh(l1_output)\n",
        "        output = self.linear2(tanh_output)\n",
        "\n",
        "        return enc_hidden_states\n",
        "'''"
      ],
      "metadata": {
        "id": "Mz4_u-QsGDkC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "2c83f13e-8e57-4697-ec1b-53c9ba767d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nclass EncoderAndClassifier(nn.Module):\\n    def __init__(self, vocab_size, enc_hid_dim, embed_dim, num_heads, output_dim, dropout=0.5):\\n        super().__init__()\\n        self.enc_hidden_dim = enc_hid_dim\\n        self.emb = nn.Embedding(vocab_size, embed_dim)\\n        self.attn = nn.MultiheadAttention(embed_dim, num_heads)\\n        self.bilstm = nn.GRU(embed_dim, enc_hid_dim, bidirectional = True)\\n        self.dropout = nn.Dropout(dropout)\\n        self.linear1 = nn.Linear(2 * enc_hid_dim, 128)\\n        self.linear2 = nn.Linear(128, output_dim)\\n\\n    def forward(self, input):\\n        # embed input tokens\\n        embedded = self.dropout(self.emb(input))\\n\\n        # process with bidirectional GRU model\\n        enc_hidden_states, _ = self.bilstm(embedded)\\n\\n        # compute a global sentence representation to feed as the initial hidden state of the decoder\\n        # concatenate the forward GRU's representation after the last word and\\n        # the backward GRU's representation after the first word\\n\\n        last_forward = enc_hidden_states[-1, :, :self.enc_hidden_dim]\\n        first_backward = enc_hidden_states[0, :, self.enc_hidden_dim:]\\n\\n        # this was from the skeleton code\\n        # transform to the size of the decoder hidden state with a fully-connected layer\\n        # sent = F.relu(self.fc(torch.cat((last_forward, first_backward), dim = 1)))\\n\\n        # should be this instead?\\n        l1_output = self.linear1(torch.cat((last_forward, first_backward), dim = 1))\\n        tanh_output = F.tanh(l1_output)\\n        output = self.linear2(tanh_output)\\n\\n        return enc_hidden_states\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Models based on Kumar et al.'s code: https://github.com/Sachin19/adversarial-classify/blob/master/model.py\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, embedding_dim, hidden_dim, nlayers=1, dropout=0., bidirectional=True):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_dim, nlayers,\n",
        "                       dropout=dropout, bidirectional=bidirectional,\n",
        "                       batch_first=True)\n",
        "\n",
        "  def forward(self, input, hidden=None):\n",
        "    self.rnn.flatten_parameters()\n",
        "    return self.rnn(input, hidden)\n",
        "\n",
        "# this one doesn't appear to be used in the Kumar et al. code\n",
        "class Attention(nn.Module):\n",
        "  def __init__(self, query_dim, key_dim, value_dim):\n",
        "    super(Attention, self).__init__()\n",
        "    self.scale = 1. / math.sqrt(query_dim)\n",
        "\n",
        "  def forward(self, query, keys, values):\n",
        "    # Query = [BxQ]\n",
        "    # Keys = [TxBxK]\n",
        "    # Values = [TxBxV]\n",
        "    # Outputs = a:[TxB], lin_comb:[BxV]\n",
        "\n",
        "    # Here we assume q_dim == k_dim (dot product attention)\n",
        "\n",
        "    query = query.unsqueeze(1) # [BxQ] -> [Bx1xQ]\n",
        "    keys = keys.transpose(0,1).transpose(1,2) # [TxBxK] -> [BxKxT]\n",
        "    energy = torch.bmm(query, keys) # [Bx1xQ]x[BxKxT] -> [Bx1xT]\n",
        "    energy = F.softmax(energy.mul_(self.scale), dim=2) # scale, normalize\n",
        "\n",
        "    values = values.transpose(0,1) # [TxBxV] -> [BxTxV]\n",
        "    linear_combination = torch.bmm(energy, values).squeeze(1) #[Bx1xT]x[BxTxV] -> [BxV]\n",
        "    return energy, linear_combination\n",
        "\n",
        "# This type of attention seems to be used\n",
        "class BahdanauAttention(nn.Module):\n",
        "  def __init__(self, hidden_dim, attn_dim):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.linear = nn.Linear(hidden_dim, attn_dim)\n",
        "    self.linear2 = nn.Linear(attn_dim, 1)\n",
        "\n",
        "  def forward(self, hidden, mask=None):\n",
        "    # hidden = [TxBxH]\n",
        "    # mask = [TxB]\n",
        "    # Outputs = a:[TxB], lin_comb:[BxV]\n",
        "\n",
        "    # Here we assume q_dim == k_dim (dot product attention)\n",
        "    # hidden = hidden.transpose(0,1) # [TxBxH] -> [BxTxH]\n",
        "    energy = self.linear(hidden) # [BxTxH] -> [BxTxA]\n",
        "    energy = F.tanh(energy)\n",
        "    energy = self.linear2(energy) # [BxTxA] -> [BxTx1]\n",
        "    energy = F.softmax(energy, dim=1) # scale, normalize\n",
        "\n",
        "    if mask is not None:\n",
        "      mask = mask.transpose(0, 1).unsqueeze(2)\n",
        "      energy = energy * mask\n",
        "      Z = energy.sum(dim=1, keepdim=True) #[BxTx1] -> [Bx1x1]\n",
        "      energy = energy/Z #renormalize\n",
        "\n",
        "    energy = energy.transpose(1, 2) # [BxTx1] -> [Bx1xT]\n",
        "    linear_combination = torch.bmm(energy, hidden).squeeze(1) #[Bx1xT]x[BxTxH] -> [BxH]\n",
        "\n",
        "    return energy, linear_combination\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self, embedding, encoder, attention, hidden_dim, num_classes=10, num_topics=50):\n",
        "    super(Classifier, self).__init__()\n",
        "    # num_classes=2\n",
        "    self.embedding = embedding\n",
        "    self.encoder = encoder\n",
        "    self.attention = attention\n",
        "    self.decoder = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    size = 0\n",
        "    for p in self.parameters():\n",
        "      size += p.nelement()\n",
        "    print('Total param size: {}'.format(size))\n",
        "\n",
        "  def forward(self, input, input_lens, alpha=1.0, gradreverse=True, padding_mask=None):\n",
        "    embedded_input = self.embedding(input)\n",
        "\n",
        "    outputs, hidden = self.encoder(embedded_input)\n",
        "\n",
        "    if isinstance(hidden, tuple): # LSTM\n",
        "      hidden = hidden[1] # take the cell state\n",
        "\n",
        "    # need to concat the last 2 hidden layers\n",
        "    hidden = torch.cat([hidden[-1], hidden[-2]], dim=-1)\n",
        "\n",
        "    energy, linear_combination = self.attention(outputs, padding_mask)\n",
        "    energy = energy.permute(2,0,1)\n",
        "\n",
        "    logits = self.decoder(linear_combination)\n",
        "    return logits, energy\n",
        "\n"
      ],
      "metadata": {
        "id": "-4-h-2T-myAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pretrain the classifier on dataset to get initial toxicity predictions\n",
        "\n",
        "def pretrain_classifier(clf, optimizer, train_loader, loss_criterion, epochs, scheduler):\n",
        "  best_model_wts = copy.deepcopy(clf.state_dict())\n",
        "  best_acc = 0.0\n",
        "  best_acc_epoch = 0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    epoch_loss = 0\n",
        "    num_items = 0\n",
        "\n",
        "    # Each epoch has a training and validation phase\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "          clf.train()  # Set model to training mode\n",
        "      else:\n",
        "          clf.eval()   # Set model to evaluate mode\n",
        "\n",
        "      if phase == 'train':\n",
        "        # data should be a tuple of (x, xlens, y, z)\n",
        "        for (input, input_lens, target_label, _) in train_loader:\n",
        "          input = input.to(device)\n",
        "          target_label = target_label.to(device)\n",
        "          num_items += input.size(0)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          classifier_output, energy = clf(input, input_lens)\n",
        "          predictions = torch.argmax(classifier_output, dim=-1)\n",
        "          classifier_loss = loss_criterion(classifier_output, target_label) # compute loss\n",
        "          classifier_loss.backward() # back prop\n",
        "          optimizer.step()\n",
        "          running_loss += classifier_loss.item() * input.size(0)\n",
        "          running_corrects += torch.sum(predictions == target_label)\n",
        "\n",
        "      epoch_loss = running_loss / num_items\n",
        "      epoch_acc = round(float(running_corrects.double() / num_items), 4)\n",
        "\n",
        "      if phase == 'val':\n",
        "        scheduler.step(epoch_acc)\n",
        "        print(f'\\nEpoch: {epoch+1} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "      # deep copy the model\n",
        "      if phase == 'val' and epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        best_acc_epoch = epoch\n",
        "        best_model_wts = copy.deepcopy(clf.state_dict())\n",
        "\n",
        "  # load best model weights\n",
        "  clf.load_state_dict(best_model_wts)\n",
        "  return clf\n",
        "\n"
      ],
      "metadata": {
        "id": "wG10O7V4JOX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(train_dataset.text_vocab)\n",
        "embed_size = 128\n",
        "hidden_size = 128\n",
        "embedding = nn.Embedding(vocab_size, embed_size, padding_idx=1)\n",
        "\n",
        "# CMU paper said: \"single-layer bidirectional LSTM encoder\"\n",
        "encoder = Encoder(embed_size, hidden_size, nlayers=1, dropout=0.5, bidirectional=True)\n",
        "\n",
        "# Kumar et al. code uses this version of attention\n",
        "# https://github.com/Sachin19/adversarial-classify/blob/master/train.py\n",
        "attention_dim = 2 * hidden_size\n",
        "attention = BahdanauAttention(attention_dim, attention_dim)\n",
        "\n",
        "clf_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "lrlast = .001\n",
        "lrmain = .00001\n",
        "\n",
        "# CMU paper mentions pre-training encoder and classifier in phase 1\n",
        "clf = Classifier(embedding, encoder, attention, attention_dim, num_classes=2)\n",
        "clf.to(device)\n",
        "\n",
        "optimizer_clf = torch.optim.Adam(clf.parameters(), lr=lrlast, amsgrad=True)\n",
        "scheduler = ReduceLROnPlateau(optimizer_clf, mode='max', patience=2, min_lr=0.000000001)\n",
        "\n",
        "# converged around 20 epochs\n",
        "clf = pretrain_classifier(clf, optimizer_clf, train_loader, clf_loss, 20, scheduler)"
      ],
      "metadata": {
        "id": "-dHc7hjhpBYZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "926a7c93-4310-4e1d-e81f-bab73dfbf5d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total param size: 3749635\n",
            "\n",
            "Epoch: 1 Loss: 0.3695 Acc: 0.8747\n",
            "\n",
            "Epoch: 2 Loss: 0.3096 Acc: 0.8795\n",
            "\n",
            "Epoch: 3 Loss: 0.2423 Acc: 0.9025\n",
            "\n",
            "Epoch: 4 Loss: 0.1953 Acc: 0.9211\n",
            "\n",
            "Epoch: 5 Loss: 0.1460 Acc: 0.9434\n",
            "\n",
            "Epoch: 6 Loss: 0.0945 Acc: 0.9664\n",
            "\n",
            "Epoch: 7 Loss: 0.0573 Acc: 0.9808\n",
            "\n",
            "Epoch: 8 Loss: 0.0372 Acc: 0.9887\n",
            "\n",
            "Epoch: 9 Loss: 0.0221 Acc: 0.9934\n",
            "\n",
            "Epoch: 10 Loss: 0.0166 Acc: 0.9949\n",
            "\n",
            "Epoch: 11 Loss: 0.0154 Acc: 0.9950\n",
            "\n",
            "Epoch: 12 Loss: 0.0158 Acc: 0.9948\n",
            "\n",
            "Epoch: 13 Loss: 0.0121 Acc: 0.9958\n",
            "\n",
            "Epoch: 14 Loss: 0.0100 Acc: 0.9965\n",
            "\n",
            "Epoch: 15 Loss: 0.0077 Acc: 0.9971\n",
            "\n",
            "Epoch: 16 Loss: 0.0082 Acc: 0.9969\n",
            "\n",
            "Epoch: 17 Loss: 0.0063 Acc: 0.9972\n",
            "\n",
            "Epoch: 18 Loss: 0.0054 Acc: 0.9976\n",
            "\n",
            "Epoch: 19 Loss: 0.0053 Acc: 0.9972\n",
            "\n",
            "Epoch: 20 Loss: 0.0046 Acc: 0.9977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get typical validation metrics\n",
        "\n",
        "def evaluate_clf(clf, data_loader):\n",
        "    all_predictions = np.empty((0,))\n",
        "    all_true_targets = np.empty((0,))\n",
        "    all_true_protected = np.empty((0,))\n",
        "\n",
        "    num_batches = 0\n",
        "    batch_metrics = {\n",
        "        \"accuracy\": 0,\n",
        "        \"precision\": 0,\n",
        "        \"recall\": 0,\n",
        "        \"f1\": 0\n",
        "    }\n",
        "\n",
        "    # Make sure there's no backprop during evaluation\n",
        "    clf.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (input, input_lens, target_label, protected_label) in enumerate(data_loader):\n",
        "            input = input.to(device)\n",
        "            target_label = target_label.to(device)\n",
        "\n",
        "            output, _ = clf(input, input_lens)\n",
        "            _, prediction = torch.max(output, 1)\n",
        "\n",
        "            target_label = target_label.to(\"cpu\")\n",
        "            prediction = prediction.to(\"cpu\")\n",
        "\n",
        "            all_predictions = np.concatenate((all_predictions, prediction.numpy()))\n",
        "            all_true_targets = np.concatenate((all_true_targets, target_label.numpy()))\n",
        "            all_true_protected = np.concatenate((all_true_protected, protected_label))\n",
        "\n",
        "    # Macro: Calculate metrics for each label, and find their unweighted mean.\n",
        "    # This does not take label imbalance into account.\n",
        "\n",
        "    # Calculate metrics for each label, and find their average weighted by support\n",
        "    # (the number of true instances for each label). This alters ‘macro’ to account\n",
        "    # for label imbalance; it can result in an F-score that is not between precision and recall.\n",
        "\n",
        "    acc_overall = accuracy_score(all_true_targets, all_predictions)\n",
        "    prec_macro = precision_score(all_true_targets, all_predictions, average=\"macro\", labels=np.unique(all_true_targets))\n",
        "    recall_macro = recall_score(all_true_targets, all_predictions, average=\"macro\", labels=np.unique(all_true_targets))\n",
        "    f1_macro = f1_score(all_true_targets, all_predictions, average=\"macro\", labels=np.unique(all_true_targets))\n",
        "    prec_weighted = precision_score(all_true_targets, all_predictions, average=\"weighted\", labels=np.unique(all_true_targets))\n",
        "    recall_weighted = recall_score(all_true_targets, all_predictions, average=\"weighted\", labels=np.unique(all_true_targets))\n",
        "    f1_weighted = f1_score(all_true_targets, all_predictions, average=\"weighted\", labels=np.unique(all_true_targets))\n",
        "\n",
        "    print(\"\\nClassifier Evaluation Results\")\n",
        "    print(\"Accuracy:\", acc_overall)\n",
        "    print(\"Precision (macro):\", prec_macro)\n",
        "    print(\"Precision (weighted):\", prec_weighted)\n",
        "    print(\"Recall (macro):\", recall_macro)\n",
        "    print(\"Recall (weighted):\", recall_weighted)\n",
        "    print(\"F1 Score (macro):\", f1_macro)\n",
        "    print(\"F1 Score (weighted):\", f1_weighted)\n",
        "\n",
        "    return (all_predictions, all_true_targets, all_true_protected)\n",
        "\n",
        "\n",
        "# Calculate fairness metrics\n",
        "\n",
        "def evaluate_clf_fairness(all_predictions, all_true_targets, all_true_protected):\n",
        "    print(\"\\n=====Fairness Metrics=====\")\n",
        "    threshold = 0.5\n",
        "    fairness_metrics = {\n",
        "        \"protected_toxicity_rate\": 0,\n",
        "        \"nonprotected_toxicity_rate\": 0,\n",
        "        \"protected_TPR\": 0,\n",
        "        \"nonprotected_TPR\": 0,\n",
        "        \"protected_FPR\": 0,\n",
        "        \"nonprotected_FPR\": 0,\n",
        "        \"demographic_parity\": 0,\n",
        "        \"true_positive_parity\": 0,\n",
        "        \"false_positive_parity\": 0,\n",
        "        \"equalized_odds\": 0\n",
        "    }\n",
        "\n",
        "    # might be easier to work with a dataframe here\n",
        "    all_data = pd.DataFrame(\n",
        "        data = {\n",
        "            \"predictions\": np.array(all_predictions),\n",
        "            \"target_labels\": np.array(all_true_targets),\n",
        "            \"protected_labels\": np.array(all_true_protected)\n",
        "        }\n",
        "    )\n",
        "    # print(all_data.head())\n",
        "\n",
        "    # Calculate toxicity rate for instances where protected label is true\n",
        "    toxic = all_data.loc[all_data[\"protected_labels\"] == 1][\"target_labels\"]\n",
        "    fairness_metrics[\"protected_toxicity_rate\"] = round(sum(toxic) / len(toxic), 4)\n",
        "\n",
        "    # Calculate toxicity rate for instances where protected label is false\n",
        "    toxic = all_data.loc[all_data[\"protected_labels\"] == 0][\"target_labels\"]\n",
        "    fairness_metrics[\"nonprotected_toxicity_rate\"] = round(sum(toxic) / len(toxic), 4)\n",
        "\n",
        "    # Calculate confusion matrix when protected label is true\n",
        "    # FPR = FP / (FP + TN)\n",
        "    # TPR = TP / (TP + FN)\n",
        "    protected = all_data.loc[all_data[\"protected_labels\"] == 1]\n",
        "    tn, fp, fn, tp = confusion_matrix(protected[\"target_labels\"], protected[\"predictions\"]).ravel()\n",
        "    fairness_metrics[\"protected_FPR\"] = fp / (fp + tn)\n",
        "    fairness_metrics[\"protected_TPR\"] = tp / (tp + fn)\n",
        "\n",
        "    # Calculate confusion matrix when protected label is true\n",
        "    nonprotected = all_data.loc[all_data[\"protected_labels\"] == 0]\n",
        "    tn, fp, fn, tp = confusion_matrix(nonprotected[\"target_labels\"], nonprotected[\"predictions\"]).ravel()\n",
        "    fairness_metrics[\"nonprotected_FPR\"] = fp / (fp + tn)\n",
        "    fairness_metrics[\"nonprotected_TPR\"] = tp / (tp + fn)\n",
        "\n",
        "    # Calculate demographic parity\n",
        "    fairness_metrics[\"demographic_parity\"] = abs(fairness_metrics[\"protected_toxicity_rate\"] - fairness_metrics[\"nonprotected_toxicity_rate\"])\n",
        "\n",
        "    # Calculate true positive parity\n",
        "    fairness_metrics[\"true_positive_parity\"] = abs(fairness_metrics[\"protected_TPR\"] - fairness_metrics[\"nonprotected_TPR\"])\n",
        "\n",
        "    # Calculate false positive parity\n",
        "    fairness_metrics[\"false_positive_parity\"] = abs(fairness_metrics[\"protected_FPR\"] - fairness_metrics[\"nonprotected_FPR\"])\n",
        "\n",
        "    # Calculate equalized odds\n",
        "    fairness_metrics[\"equalized_odds\"] = fairness_metrics[\"true_positive_parity\"] + fairness_metrics[\"false_positive_parity\"]\n",
        "\n",
        "    return fairness_metrics\n",
        "\n",
        "\n",
        "all_predictions, all_true_targets, all_true_protected = evaluate_clf(clf, test_loader)\n",
        "evaluate_clf_fairness(all_predictions, all_true_targets, all_true_protected)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdPMAmpmvtY1",
        "outputId": "6ece4cf4-6954-44fe-c1a7-2b4de0774da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classifier Evaluation Results\n",
            "Accuracy: 0.8706481546082467\n",
            "Precision (macro): 0.7145142401303506\n",
            "Precision (weighted): 0.857434209038154\n",
            "Recall (macro): 0.6661876952603957\n",
            "Recall (weighted): 0.8706481546082467\n",
            "F1 Score (macro): 0.6853615776134209\n",
            "F1 Score (weighted): 0.8624611124753722\n",
            "\n",
            "=====Fairness Metrics=====\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'protected_toxicity_rate': 0.2454,\n",
              " 'nonprotected_toxicity_rate': 0.0937,\n",
              " 'protected_TPR': 0.4525627044711014,\n",
              " 'nonprotected_TPR': 0.32729103726082576,\n",
              " 'protected_FPR': 0.12061014544164597,\n",
              " 'nonprotected_FPR': 0.03581840899625156,\n",
              " 'demographic_parity': 0.1517,\n",
              " 'true_positive_parity': 0.12527166721027566,\n",
              " 'false_positive_parity': 0.08479173644539441,\n",
              " 'equalized_odds': 0.21006340365567006}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Two-layer MLP with tanh activation for the Adversary\n",
        "class Adversary(nn.Module):\n",
        "    def __init__(self, hidden_dim, output_dim, encoder, embedding):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = embedding\n",
        "        self.encoder = encoder\n",
        "        self.linear1 = nn.Linear(hidden_dim * 2, 128)\n",
        "        self.linear2 = nn.Linear(128, output_dim)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded_input = self.embedding(input)\n",
        "        outputs, hidden = self.encoder(embedded_input)\n",
        "\n",
        "        if isinstance(hidden, tuple): # LSTM\n",
        "          hidden = hidden[1] # take the cell state\n",
        "\n",
        "        # need to concat the last 2 hidden layers\n",
        "        hidden = torch.cat([hidden[-1], hidden[-2]], dim=-1)\n",
        "\n",
        "        l1_output = self.linear1(hidden.to(torch.float))\n",
        "        tanh_output = F.tanh(l1_output)\n",
        "        output = self.linear2(tanh_output)\n",
        "        return output\n",
        "\n",
        "adv = Adversary(hidden_size, 2, encoder, embedding)\n",
        "adv.to(device)\n",
        "\n",
        "optimizer_adv = optim.Adam(adv.parameters(), lr=lrlast)\n",
        "adv_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# CMU paper doesn't mention pretraining the adversary"
      ],
      "metadata": {
        "id": "sBLfGHhfRDe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Below is code from the other adversarial debiasing architecture, can probably adapt it"
      ],
      "metadata": {
        "id": "R_omJbLFpBtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the adversary, worry only about adversary's loss\n",
        "\n",
        "def train_adversary(adv, clf, optimizer_adv, train_loader, loss_criterion, epochs=1):\n",
        "    adv_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    # data should be a tuple of (x, y, z)\n",
        "    for i, (input, input_lens, target_label, protected_label) in enumerate(train_loader):\n",
        "        input = input.to(device)\n",
        "        protected_label = protected_label.to(device)\n",
        "\n",
        "        optimizer_adv.zero_grad()\n",
        "\n",
        "        # clf_output, clf_prev_output = clf(input, input_lens)\n",
        "        adv_output = adv(input)\n",
        "        adv_loss = loss_criterion(adv_output, protected_label)\n",
        "        # adv_loss.requires_grad = True\n",
        "        # adv_loss.retain_grad()\n",
        "        adv_loss.backward() # back prop\n",
        "        optimizer_adv.step()\n",
        "        adv_loss += adv_loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    print(\"\\tAdversary epoch loss: \", adv_loss.item())\n",
        "\n",
        "    return adv\n",
        "\n",
        "\n",
        "# Train the classifier, but need to combine two objectives using alpha parameter\n",
        "# minimize clf loss and try to make adversary guess closer to random\n",
        "\n",
        "def train_classifier(clf, optimizer_clf, adv, train_loader, clf_criterion, adv_criterion, alpha_val):\n",
        "    # data should be a tuple of (x, y, z)\n",
        "    for (input, input_lens, target_label, protected_label) in train_loader:\n",
        "        input = input.to(device)\n",
        "        target_label = target_label.to(device)\n",
        "\n",
        "        # batch of protected labels should be randomly sampled from uniform(0,1)\n",
        "        # to confuse the adversary\n",
        "        protected_label = torch.rand(size=protected_label.shape)\n",
        "        protected_label = torch.bernoulli(protected_label).type(torch.LongTensor)\n",
        "        protected_label = protected_label.to(device)\n",
        "\n",
        "        optimizer_clf.zero_grad()\n",
        "\n",
        "        clf_output, clf_prev_output = clf(input, input_lens)\n",
        "        adv_output = adv(input)\n",
        "        adv_loss = adv_criterion(adv_output, protected_label)\n",
        "        clf_loss = clf_criterion(clf_output, target_label)\n",
        "        total_classifier_loss = alpha_val * clf_loss + (1-alpha_val) * adv_loss\n",
        "        # clf_loss.retain_grad()\n",
        "        # adv_loss.retain_grad()\n",
        "        total_classifier_loss.backward() # back prop\n",
        "\n",
        "        optimizer_clf.step()\n",
        "\n",
        "        print(\"\\tClassifier epoch loss: \", total_classifier_loss.item())\n",
        "\n",
        "        break\n",
        "\n",
        "    return clf\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8d9HF4f_gWjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In phase 2, alternate training between the classifier and the adversary\n",
        "# Train adversary using equation 2, input: encoder outputs, output: protected label prediction\n",
        "# Train classifier using equation 3\n",
        "# Encoder produces samples that will make adversary predict closer to random, input: ?, output: ?\n",
        "# Clf input: encoder outputs, output: target label prediction\n",
        "\n",
        "# More text from the paper:\n",
        "\n",
        "# In the pre-training phase, we train the model until convergence and pick the\n",
        "# best-performing checkpoint for fine-tuning. In the fine-tuning phase, we\n",
        "# alternate training one single adversary and the classification model each for\n",
        "# two epochs in one round and train for 10 rounds in total\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=train_dataset.pad_collate)\n",
        "\n",
        "num_iterations = 10\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    print(\"\\n===== Iteration\", iteration, \"=====\")\n",
        "\n",
        "    for e in range(2):\n",
        "        print(\"\\tEpoch\", e+1)\n",
        "\n",
        "        # Train adversary for 2 epochs\n",
        "\n",
        "        for param in clf.parameters():\n",
        "          param.requires_grad = False\n",
        "\n",
        "        adv_loss.requires_grad = True\n",
        "        adv = train_adversary(adv, clf, optimizer_adv, train_loader, adv_loss, epochs=1)\n",
        "\n",
        "        for param in clf.parameters():\n",
        "          param.requires_grad = True\n",
        "\n",
        "        # Train classifier for 2 epochs\n",
        "\n",
        "        for param in adv.parameters():\n",
        "          param.requires_grad = False\n",
        "\n",
        "        clf_loss.requires_grad = True\n",
        "        # The paper set alpha to 0.05\n",
        "        clf = train_classifier(clf, optimizer_clf, adv, train_loader, clf_loss, adv_loss, 0.5)\n",
        "\n",
        "        for param in adv.parameters():\n",
        "          param.requires_grad = True\n",
        "\n",
        "    # Evaluate classifier\n",
        "    if iteration % 2 == 0:\n",
        "      all_predictions, all_true_targets, all_true_protected = evaluate_clf(clf, val_loader)\n",
        "      evaluate_clf_fairness(all_predictions, all_true_targets, all_true_protected)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b39fYKySTO8S",
        "outputId": "ee74a41c-c71e-4431-b2b9-4c6942348f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Iteration 0 =====\n",
            "\tEpoch 1\n",
            "\tAdversary epoch loss:  1.0371233224868774\n",
            "\tClassifier epoch loss:  0.4794791340827942\n",
            "\tEpoch 2\n",
            "\tAdversary epoch loss:  1.1495082378387451\n",
            "\tClassifier epoch loss:  0.443795770406723\n",
            "\n",
            "Classifier Evaluation Results\n",
            "Accuracy: 0.8695\n",
            "Precision (macro): 0.7113437370374107\n",
            "Precision (weighted): 0.8559719206493346\n",
            "Recall (macro): 0.6631737979493142\n",
            "Recall (weighted): 0.8695\n",
            "F1 Score (macro): 0.682200843660568\n",
            "F1 Score (weighted): 0.8611316776573628\n",
            "\n",
            "=====Fairness Metrics=====\n",
            "\n",
            "===== Iteration 1 =====\n",
            "\tEpoch 1\n",
            "\tAdversary epoch loss:  1.3110564947128296\n",
            "\tClassifier epoch loss:  0.45724138617515564\n",
            "\tEpoch 2\n",
            "\tAdversary epoch loss:  0.9699040651321411\n",
            "\tClassifier epoch loss:  0.36290985345840454\n",
            "\n",
            "===== Iteration 2 =====\n",
            "\tEpoch 1\n",
            "\tAdversary epoch loss:  1.2289257049560547\n",
            "\tClassifier epoch loss:  0.4953964948654175\n",
            "\tEpoch 2\n",
            "\tAdversary epoch loss:  1.1549842357635498\n",
            "\tClassifier epoch loss:  0.5216394662857056\n",
            "\n",
            "Classifier Evaluation Results\n",
            "Accuracy: 0.8692\n",
            "Precision (macro): 0.7107492000807525\n",
            "Precision (weighted): 0.8561907728727125\n",
            "Recall (macro): 0.6649051497903897\n",
            "Recall (weighted): 0.8692\n",
            "F1 Score (macro): 0.6832450891606954\n",
            "F1 Score (weighted): 0.8612395183039296\n",
            "\n",
            "=====Fairness Metrics=====\n",
            "\n",
            "===== Iteration 3 =====\n",
            "\tEpoch 1\n",
            "\tAdversary epoch loss:  0.8389912843704224\n",
            "\tClassifier epoch loss:  0.49356263875961304\n",
            "\tEpoch 2\n",
            "\tAdversary epoch loss:  0.9990437030792236\n",
            "\tClassifier epoch loss:  0.4858091175556183\n",
            "\n",
            "===== Iteration 4 =====\n",
            "\tEpoch 1\n",
            "\tAdversary epoch loss:  0.9550520181655884\n",
            "\tClassifier epoch loss:  0.5181239247322083\n",
            "\tEpoch 2\n",
            "\tAdversary epoch loss:  0.8990207314491272\n",
            "\tClassifier epoch loss:  0.42493608593940735\n",
            "\n",
            "Classifier Evaluation Results\n",
            "Accuracy: 0.8688\n",
            "Precision (macro): 0.7099609722729021\n",
            "Precision (weighted): 0.8564187833554437\n",
            "Recall (macro): 0.6668962152272232\n",
            "Recall (weighted): 0.8688\n",
            "F1 Score (macro): 0.6843821916115715\n",
            "F1 Score (weighted): 0.8613209941653045\n",
            "\n",
            "=====Fairness Metrics=====\n",
            "\n",
            "===== Iteration 5 =====\n",
            "\tEpoch 1\n",
            "\tAdversary epoch loss:  0.8290727734565735\n",
            "\tClassifier epoch loss:  0.4899461567401886\n",
            "\tEpoch 2\n",
            "\tAdversary epoch loss:  1.1537386178970337\n",
            "\tClassifier epoch loss:  0.46264612674713135\n",
            "\n",
            "===== Iteration 6 =====\n",
            "\tEpoch 1\n",
            "\tAdversary epoch loss:  1.22580885887146\n",
            "\tClassifier epoch loss:  0.4650271236896515\n",
            "\tEpoch 2\n",
            "\tAdversary epoch loss:  1.110117793083191\n",
            "\tClassifier epoch loss:  0.4171181619167328\n",
            "\n",
            "Classifier Evaluation Results\n",
            "Accuracy: 0.8687\n",
            "Precision (macro): 0.7098153499799764\n",
            "Precision (weighted): 0.8565735393057766\n",
            "Recall (macro): 0.6677907361921823\n",
            "Recall (weighted): 0.8687\n",
            "F1 Score (macro): 0.6849523173052765\n",
            "F1 Score (weighted): 0.8614097619671991\n",
            "\n",
            "=====Fairness Metrics=====\n",
            "\n",
            "===== Iteration 7 =====\n",
            "\tEpoch 1\n",
            "\tAdversary epoch loss:  1.0353150367736816\n",
            "\tClassifier epoch loss:  0.42062366008758545\n",
            "\tEpoch 2\n",
            "\tAdversary epoch loss:  1.408578872680664\n",
            "\tClassifier epoch loss:  0.40844103693962097\n",
            "\n",
            "===== Iteration 8 =====\n",
            "\tEpoch 1\n",
            "\tAdversary epoch loss:  1.1321666240692139\n",
            "\tClassifier epoch loss:  0.5410817265510559\n",
            "\tEpoch 2\n",
            "\tAdversary epoch loss:  1.0821367502212524\n",
            "\tClassifier epoch loss:  0.5536707639694214\n",
            "\n",
            "Classifier Evaluation Results\n",
            "Accuracy: 0.8681\n",
            "Precision (macro): 0.7083092128272852\n",
            "Precision (weighted): 0.8561277841094106\n",
            "Recall (macro): 0.667444595659126\n",
            "Recall (weighted): 0.8681\n",
            "F1 Score (macro): 0.6842067888645137\n",
            "F1 Score (weighted): 0.8609428405573004\n",
            "\n",
            "=====Fairness Metrics=====\n",
            "\n",
            "===== Iteration 9 =====\n",
            "\tEpoch 1\n",
            "\tAdversary epoch loss:  0.8977882266044617\n",
            "\tClassifier epoch loss:  0.4117443263530731\n",
            "\tEpoch 2\n",
            "\tAdversary epoch loss:  0.9520902633666992\n",
            "\tClassifier epoch loss:  0.4378586709499359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set at the end\n",
        "all_predictions, all_true_targets, all_true_protected = evaluate_clf(clf, test_loader)\n",
        "evaluate_clf_fairness(all_predictions, all_true_targets, all_true_protected)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhgxhMryn-JW",
        "outputId": "a01f94c1-f550-4805-bdc6-e602fae840c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classifier Evaluation Results\n",
            "Accuracy: 0.8685550826763413\n",
            "Precision (macro): 0.7096438608795034\n",
            "Precision (weighted): 0.8570570502159683\n",
            "Recall (macro): 0.67007549752549\n",
            "Recall (weighted): 0.8685550826763413\n",
            "F1 Score (macro): 0.6864555979032769\n",
            "F1 Score (weighted): 0.8617198919085158\n",
            "\n",
            "=====Fairness Metrics=====\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'protected_toxicity_rate': 0.2454,\n",
              " 'nonprotected_toxicity_rate': 0.0937,\n",
              " 'protected_TPR': 0.46673936750272627,\n",
              " 'nonprotected_TPR': 0.337361530715005,\n",
              " 'protected_FPR': 0.12876906704505145,\n",
              " 'nonprotected_FPR': 0.03894210745522699,\n",
              " 'demographic_parity': 0.1517,\n",
              " 'true_positive_parity': 0.12937783678772125,\n",
              " 'false_positive_parity': 0.08982695958982445,\n",
              " 'equalized_odds': 0.2192047963775457}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on val set one more time\n",
        "all_predictions, all_true_targets, all_true_protected = evaluate_clf(clf, val_loader)\n",
        "evaluate_clf_fairness(all_predictions, all_true_targets, all_true_protected)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zcri8ob9ukv",
        "outputId": "5fcbbfb3-673b-4666-a3ce-273ea548223b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classifier Evaluation Results\n",
            "Accuracy: 0.69\n",
            "Precision (macro): 0.6116259362528019\n",
            "Precision (weighted): 0.6781061724345306\n",
            "Recall (macro): 0.6020445296863274\n",
            "Recall (weighted): 0.69\n",
            "F1 Score (macro): 0.6055056948688864\n",
            "F1 Score (weighted): 0.6830622653522421\n",
            "\n",
            "=====Fairness Metrics=====\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'protected_toxicity_rate': 0.3126,\n",
              " 'nonprotected_toxicity_rate': 0.2781,\n",
              " 'protected_TPR': 0.4074074074074074,\n",
              " 'nonprotected_TPR': 0.38966202783300197,\n",
              " 'protected_FPR': 0.18947368421052632,\n",
              " 'nonprotected_FPR': 0.19142419601837674,\n",
              " 'demographic_parity': 0.034499999999999975,\n",
              " 'true_positive_parity': 0.017745379574405418,\n",
              " 'false_positive_parity': 0.0019505118078504136,\n",
              " 'equalized_odds': 0.01969589138225583}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fgtpe0HoM3g4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}